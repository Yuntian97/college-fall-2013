# Activity Selection Problem

## Methodology

The method that I used to calculate the performance of the three different
algorithms was quite simple. I made use of the function `System.nanoTime()` to
get the nano seconds. By calling it before and after the method and taking the
difference of each result, I was able to determine the nano seconds that it
took for the method to run.

    Note: Have a look at the Runner.java class to see the code that I used to
    generate these results.

To ensure that the times I gathered weren't affected by OS scheduling or
anything else, I ran each test 100 times and averaged the results each time.

For each one of the 100 rounds, I would generate a random set of n
intervals, where n was a power of 2. Each scheduler would then run on this
random set of intervals.

## Expectations

Based on Big-Oh analysis, each of the brute force schedulers is expected to run
in O(2^n) time. This is because each subset needs to be checked. Even though
the smart brute force scheduler tries to do it intelligently, in the worst case
it will need to evaluate almost all the subsets. Therefore it will still be
close to O(2^n) for the average case because if it only looks at half of the
subsets, that just equals O(2^n / 2) = O(2^{n - 1}) which is still O(2^n).

The Big-Oh analysis for the Earliest Deadline algorithm is O(nlgn) if the input is
sorted by finish time. However, in this case, the input isn't sorted so we do
that first. Thus the complexity is then O(nlgn + n) which is just O(nlgn)
asymptotically. This is because Earliest deadline is greedy and selects the
best possible optimal interval at each step. This can be run in linear time.
Since the sorting dominates the linear traversal, it wins out in the Big Oh
analysis. A proof of the linear greediness of the problem can be constructed
like here:
http://en.wikipedia.org/wiki/Activity_selection_problem#Proof_of_optimality

Based on this analysis, we can expect the time for input sizes n and 2n to grow
exponentially for the brute force methods.

However, for the greedy method, the time for input of size n and 2n should only
grow at a linear-log rate, indicating a slower growth.

## Results

The results for the analysis are in the table below. The first column indicates
the size of the input. The next three columns indicate the scheduler used to
determine the optimal set. The last three columns take the time for input size
n and divides it by the time it took for input size (n / 2).

By dividing the time by the previous time, we can see what happens everytime
the input size of n is doubled.

    n |               Brute |               Smart |            Earliest |        Brute Growth |        Smart Growth |     Earliest Growth |
    1 |                8535 |                7010 |                4022 |                 DNE |                 DNE |                 DNE |
    2 |               13331 |                8401 |                4659 |             1.56192 |             1.19843 |             1.15838 |
    4 |               46072 |               12826 |                5975 |             3.45600 |             1.52672 |             1.28246 |
    8 |              847610 |               65907 |               13525 |             18.3975 |             5.13855 |             2.26360 |


## Conclusion

As the results show, both brute force schedulers grow exponentially when the
input size is doubled. The Smart Growth grows slightly slower than exponential,
but it still isn't close to being better. Yet the greedy scheduler
approximately doubles with the input size. This is exactly what the Big Oh
analysis predicted.

Thus it shows that Big Oh is a very valid way for comparing runtime of
algorithms.

The power of asymptotics is great =D
